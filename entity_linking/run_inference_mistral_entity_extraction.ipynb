{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff1289-7310-4d18-99bb-cddda849ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "import nltk\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "random.seed(42)\n",
    "from helpers import *\n",
    "from retriever import *\n",
    "nltk.download('punkt')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78bb06-5dd8-4b6b-8115-a89f7371a183",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34fae9e-2411-4fc2-bcbd-277d1a2c6c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoPeftModelForCausalLM.from_pretrained(\"entity_finetune/\",  torch_dtype=torch.bfloat16).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c06411",
   "metadata": {},
   "source": [
    "## Load test set subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa897c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_subsample = read_jsonl_file(\"test_set_subsample.jsonl\")\n",
    "few_shot_example = read_jsonl_file(\"mesh_few_shot_prompt.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f033938-5c11-4d92-af9a-544d0ae48934",
   "metadata": {},
   "source": [
    "# Evaluate fine-tuned Mistral performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4732f8b-462d-4b31-a6b9-ec0b248a60d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_few_shot_answers = []\n",
    "for item in tqdm(test_set_subsample):\n",
    "    few_shot_prompt_messages = build_entity_prompt(item)\n",
    "    prompt = tokenizer.apply_chat_template(few_shot_prompt_messages, tokenize=False)\n",
    "    tensors = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = tensors.input_ids.cuda()\n",
    "    attention_mask = tensors.attention_mask.cuda()\n",
    "    outputs = model.generate(input_ids = input_ids, attention_mask = attention_mask, max_new_tokens=200, do_sample=False)    \n",
    "    # https://github.com/huggingface/transformers/issues/17117#issuecomment-1124497554\n",
    "    gen_text = tokenizer.batch_decode(outputs.detach().cpu().numpy()[:, input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
    "    mistral_few_shot_answers.append(parse_entities_from_trained_model(gen_text.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e9ecea",
   "metadata": {},
   "source": [
    "## Set up BM-25 retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6706ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_data = read_jsonl_file(\"mesh_2020.jsonl\")\n",
    "process_mesh_kb(mesh_data)\n",
    "mesh_data_kb = {x[\"concept_id\"]:x for x in mesh_data}\n",
    "entity_mesh_data_dict = [[x[\"concept_id\"] , \" \".join(x[\"aliases\"].split(\",\")) + \" \" + x[\"canonical_name\"]] for x in mesh_data]\n",
    "entity_ranker = BM25Retriever(entity_mesh_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3641f999-9304-442f-9743-ac9ed6cbcec4",
   "metadata": {},
   "source": [
    "### Evaluate Finetuned LLM + Retriever Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9060b237-a14e-495e-be32-22a2155f5729",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_answers = []\n",
    "\n",
    "for item in tqdm(mistral_few_shot_answers):\n",
    "    answer_element = []\n",
    "    for entity in item:\n",
    "        retrieved_mesh_ids = entity_ranker.query(entity, top_n = 1)\n",
    "        answer_element.append({\"identifier\":retrieved_mesh_ids[0], \"text\":entity})\n",
    "    retrieved_answers.append(answer_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47afb2b2-8060-4318-89a5-1d0d704967d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_scores = [calculate_entity_metrics(gt[\"annotations\"],pred) for gt, pred in zip(test_set_subsample, retrieved_answers)]\n",
    "macro_precision_entity = sum([x[0] for x in entity_scores]) / len(entity_scores)\n",
    "macro_recall_entity = sum([x[1] for x in entity_scores]) / len(entity_scores)\n",
    "macro_f1_entity = sum([x[2] for x in entity_scores]) / len(entity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa45bd0-444b-426d-bce9-7016202d719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_scores = [calculate_mesh_metrics(gt[\"annotations\"],pred) for gt, pred in zip(test_set_subsample, retrieved_answers)]\n",
    "macro_precision_mesh = sum([x[0] for x in mesh_scores]) / len(mesh_scores)\n",
    "macro_recall_mesh = sum([x[1] for x in mesh_scores]) / len(mesh_scores)\n",
    "macro_f1_mesh = sum([x[2] for x in mesh_scores]) / len(mesh_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605793e-a610-46d9-b6f4-4240a38b77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame([[\"Entity Extraction\", macro_precision_entity, macro_recall_entity, macro_f1_entity], [\"Entity Linking\", macro_precision_mesh, macro_recall_mesh,macro_f1_mesh]])\n",
    "scores_df.columns = [\"Task\", \"Macro Precision\", \"Macro Recall\", \"Macro F1\"]\n",
    "scores_df['Macro Precision'] = scores_df['Macro Precision'].apply(lambda x: f'{x * 100:.2f}%')\n",
    "scores_df['Macro Recall'] = scores_df['Macro Recall'].apply(lambda x: f'{x * 100:.2f}%')\n",
    "scores_df['Macro F1'] = scores_df['Macro F1'].apply(lambda x: f'{x * 100:.2f}%')\n",
    "scores_df.to_csv(\"finetuned_model_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5963d48c-9abf-4617-8c0f-da1bd3eb53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"finetuned_predictions.json\", \"w\") as file:\n",
    "    file.write(json.dumps({\"predictions\": retrieved_answers}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
