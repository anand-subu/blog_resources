{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecf4c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "key = \"\"\n",
    "\n",
    "client = OpenAI(api_key= key)\n",
    "\n",
    "def write_jsonl_file(file_path, dict_list):\n",
    "    \"\"\"\n",
    "    Write a list of dictionaries to a JSON Lines file.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): The path to the file where the data will be written.\n",
    "    - dict_list (list): A list of dictionaries to write to the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        for dictionary in dict_list:\n",
    "            # Convert the dictionary to a JSON string and write it to the file.\n",
    "            json_line = json.dumps(dictionary)\n",
    "            file.write(json_line + '\\n')\n",
    "\n",
    "def read_jsonl_file(file_path):\n",
    "    \"\"\"\n",
    "    Parses a JSONL (JSON Lines) file and returns a list of dictionaries.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSONL file to be read.\n",
    "\n",
    "    Returns:\n",
    "        list of dict: A list where each element is a dictionary representing\n",
    "            a JSON object from the file.\n",
    "    \"\"\"\n",
    "    jsonl_lines = []\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            json_object = json.loads(line)\n",
    "            jsonl_lines.append(json_object)\n",
    "            \n",
    "    return jsonl_lines\n",
    "\n",
    "def create_query(item):\n",
    "    \"\"\"\n",
    "    Creates the input for the model using the question and the multiple choice options.\n",
    "\n",
    "    Args:\n",
    "        item (dict): A dictionary containing the question and options.\n",
    "            Expected keys are \"question\" and \"options\", where \"options\" is another\n",
    "            dictionary with keys \"A\", \"B\", \"C\", and \"D\".\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted query combining the question and options, ready for use.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"## Question {item[\"question\"]}\n",
    "A. {item[\"options\"][\"A\"]}             \n",
    "B. {item[\"options\"][\"B\"]}\n",
    "C. {item[\"options\"][\"C\"]}\n",
    "D. {item[\"options\"][\"D\"]}\"\"\"\n",
    "    \n",
    "    return query\n",
    "\n",
    "def build_zero_shot_prompt(system_prompt, question):\n",
    "    \"\"\"\n",
    "    Builds the zero-shot prompt.\n",
    "\n",
    "    Args:\n",
    "        system_prompt (str): Task Instruction for the LLM\n",
    "        content (dict): The content for which to create a query, formatted as\n",
    "            required by `create_query`.\n",
    "\n",
    "    Returns:\n",
    "        list of dict: A list of messages, including a system message defining\n",
    "            the task and a user message with the input question.\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": create_query(question)}]\n",
    "    return messages\n",
    "\n",
    "def format_answer(cot, answer):\n",
    "    return f\"\"\"## Answer\n",
    "{cot}\n",
    "Therefore, the answer is {answer}\"\"\"\n",
    "\n",
    "def build_few_shot_prompt(system_prompt, question, examples, include_cot=True):\n",
    "    \"\"\"\n",
    "    Builds the few-shot prompt.\n",
    "\n",
    "    Args:\n",
    "        system_prompt (str): Task Instruction for the LLM\n",
    "        content (dict): The content for which to create a query, formatted as\n",
    "            required by `create_query`.\n",
    "\n",
    "    Returns:\n",
    "        list of dict: A list of messages, including a system message defining\n",
    "            the task and a user message with the input question.\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    \n",
    "    for elem in examples:\n",
    "        messages.append({\"role\": \"user\", \"content\": create_query(elem)})\n",
    "        if include_cot:\n",
    "            messages.append({\"role\": \"assistant\", \"content\": format_answer(elem[\"cot\"], elem[\"answer_idx\"])})        \n",
    "        else:           \n",
    "            answer_string = f\"\"\"## Answer\\nTherefore, the answer is {elem[\"answer_idx\"]}\"\"\"\n",
    "            messages.append({\"role\": \"assistant\", \"content\": answer_string})\n",
    "            \n",
    "    messages.append({\"role\": \"user\", \"content\": create_query(question)})\n",
    "    return messages\n",
    "\n",
    "def get_response(messages, model_name, temperature = 0.0, max_tokens = 10):\n",
    "    \"\"\"\n",
    "    Obtains the responses/answers of the model through the chat-completions API.\n",
    "\n",
    "    Args:\n",
    "        messages (list of dict): The built messages provided to the API.\n",
    "        model_name (str): Name of the model to access through the API\n",
    "        temperature (float): A value between 0 and 1 that controls the randomness of the output.\n",
    "        A temperature value of 0 ideally makes the model pick the most likely token, making the outputs deterministic.\n",
    "        max_tokens (int): Maximum number of tokens that the model should generate\n",
    "\n",
    "    Returns:\n",
    "        str: The response message content from the model.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def matches_ans_option(s):\n",
    "    \"\"\"\n",
    "    Checks if the string starts with the specific pattern 'Therefore, the answer is [A-Z]'.\n",
    "    \n",
    "    Args:\n",
    "    s (str): The string to be checked.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the string matches the pattern, False otherwise.\n",
    "    \"\"\"\n",
    "    return bool(re.match(r'^Therefore, the answer is [A-Z]', s))\n",
    "\n",
    "def extract_ans_option(s):\n",
    "    \"\"\"\n",
    "    Extracts the answer option (a single capital letter) from the start of the string.\n",
    "    \n",
    "    Args:\n",
    "    s (str): The string containing the answer pattern.\n",
    "\n",
    "    Returns:\n",
    "    str or None: The captured answer option if the pattern is found, otherwise None.\n",
    "    \"\"\"\n",
    "    match = re.search(r'^Therefore, the answer is ([A-Z])', s)\n",
    "    if match:\n",
    "        return match.group(1)  # Returns the captured alphabet\n",
    "    return None \n",
    "\n",
    "def matches_answer_start(s):\n",
    "    \"\"\"\n",
    "    Checks if the string starts with the markdown header '## Answer'.\n",
    "    \n",
    "    Args:\n",
    "    s (str): The string to be checked.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the string starts with '## Answer', False otherwise.\n",
    "    \"\"\"\n",
    "    return s.startswith(\"## Answer\")\n",
    "\n",
    "def validate_response(s):\n",
    "    \"\"\"\n",
    "    Validates a multi-line string response that it starts with '## Answer' and ends with the answer pattern.\n",
    "    \n",
    "    Args:\n",
    "    s (str): The multi-line string response to be validated.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the response is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    file_content = s.split(\"\\n\")\n",
    "    \n",
    "    return matches_ans_option(file_content[-1]) and matches_answer_start(s)\n",
    "\n",
    "def parse_answer(response):\n",
    "    \"\"\"\n",
    "    Parses a response that starts with '## Answer', extracting the reasoning and the answer choice.\n",
    "    \n",
    "    Args:\n",
    "    response (str): The multi-line string response containing the answer and reasoning.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the extracted CoT reasoning and the answer choice.\n",
    "    \"\"\"\n",
    "    split_response = response.split(\"\\n\")\n",
    "    assert split_response[0] == \"## Answer\"\n",
    "    cot_reasoning = \"\\n\".join(split_response[1:-1]).strip()\n",
    "    ans_choice = extract_ans_option(split_response[-1])\n",
    "    return cot_reasoning, ans_choice\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"You are an expert medical professional. You are provided with a medical question with multiple answer choices.\n",
    "Your goal is to think through the question carefully and explain your reasoning step by step before selecting the final answer.\n",
    "Respond only with the reasoning steps and answer as specified below.\n",
    "Below is the format for each question and answer:\n",
    "\n",
    "Input:\n",
    "## Question: {{question}}\n",
    "{{answer_choices}}\n",
    "\n",
    "Output:\n",
    "## Answer\n",
    "(model generated chain of thought explanation)\n",
    "Therefore, the answer is [final model answer (e.g. A,B,C,D)]\"\"\"\n",
    "\n",
    "system_zero_shot_prompt = \"\"\"You are an expert medical professional. You are provided with a medical question with multiple answer choices.\n",
    "Your goal is to think through the question carefully and respond directly with the answer option.\n",
    "Below is the format for each question and answer:\n",
    "\n",
    "Input:\n",
    "## Question: {{question}}\n",
    "{{answer_choices}}\n",
    "\n",
    "Output:\n",
    "## Answer\n",
    "Therefore, the answer is [final model answer (e.g. A,B,C,D)]\"\"\"\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5504d3",
   "metadata": {},
   "source": [
    "## Generate chain of thoughts embeddings for datapoints in the development set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa84cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_jsonl_file(\"data/phrases_no_exclude_train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_responses = []\n",
    "os.mkdir(\"cot_responses\")\n",
    "\n",
    "for idx, item in enumerate(tqdm(train_data)):    \n",
    "    prompt = build_zero_shot_prompt(system_prompt, item)\n",
    "    try:\n",
    "        response = get_response(prompt, model_name=\"gpt-4o\", max_tokens=500)\n",
    "        cot_responses.append(response)\n",
    "        with open(os.path.join(\"cot_responses\", str(idx) + \".txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response)           \n",
    "    except Exception as e :\n",
    "        print(str(e))\n",
    "        cot_responses.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0665a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_dict = []\n",
    "ctr = 0\n",
    "for idx, question in enumerate(tqdm(train_data)):\n",
    "    file =  open(os.path.join(\"cot_responses\", str(idx) + \".txt\"), encoding=\"utf-8\").read()\n",
    "    if not validate_response(file):\n",
    "        continue\n",
    "    \n",
    "    cot, pred_ans = parse_answer(file)\n",
    "    \n",
    "    dict_elem = {}\n",
    "    dict_elem[\"idx\"] = idx\n",
    "    dict_elem[\"question\"] = question[\"question\"]\n",
    "    dict_elem[\"answer\"] = question[\"answer\"]\n",
    "    dict_elem[\"options\"] = question[\"options\"]\n",
    "    dict_elem[\"cot\"] = cot\n",
    "    dict_elem[\"pred_ans\"] = pred_ans\n",
    "    questions_dict.append(dict_elem)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0960944",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl_file(\"cot_responses_medqa_train_set.jsonl\", questions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7612cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_dict = read_jsonl_file(\"cot_responses_medqa_train_set.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a5abe",
   "metadata": {},
   "source": [
    "## Filter questions whose predicted answer does not match the actual answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f8ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_questions_dict = []\n",
    "for item in tqdm(questions_dict):\n",
    "    pred_ans = item[\"options\"][item[\"pred_ans\"]]\n",
    "    if pred_ans == item[\"answer\"]:\n",
    "        filtered_questions_dict.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ef7a5",
   "metadata": {},
   "source": [
    "## Embed all questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb8a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tqdm(filtered_questions_dict):\n",
    "    item[\"embedding\"] = get_embedding(item[\"question\"])\n",
    "    inv_options_map = {v:k for k,v in item[\"options\"].items()}\n",
    "    item[\"answer_idx\"] = inv_options_map[item[\"answer\"]]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a78293",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl_file(\"cot_responses_medqa_train_set_filtered_with_embeddings.jsonl\", filtered_questions_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4cf3a8",
   "metadata": {},
   "source": [
    "## Fit K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86263c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_questions_dict = read_jsonl_file(\"cot_responses_medqa_train_set_filtered_with_embeddings.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca39110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Extract embeddings and keep track of indices\n",
    "embeddings = np.array([d[\"embedding\"] for d in filtered_questions_dict])\n",
    "indices = list(range(len(filtered_questions_dict)))\n",
    "\n",
    "# Train KNN model\n",
    "knn = NearestNeighbors(n_neighbors=3, algorithm='auto', metric='cosine').fit(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7878dc9",
   "metadata": {},
   "source": [
    "## Implement inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69057198",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = read_jsonl_file(\"test_data_usmle_subsampled.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe861301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_option_labels(answer_options):\n",
    "    \"\"\"\n",
    "    Shuffles the options of the question.\n",
    "    \n",
    "    Parameters:\n",
    "    answer_options (dict): A dictionary with the options.\n",
    "\n",
    "    Returns:\n",
    "    dict: A new dictionary with the shuffled options.\n",
    "    \"\"\"\n",
    "    options = list(answer_options.values())\n",
    "    random.shuffle(options)\n",
    "    labels = [chr(i) for i in range(ord('A'), ord('A') + len(options))]\n",
    "    shuffled_options_dict = {label: option for label, option in zip(labels, options)}\n",
    "    \n",
    "    return shuffled_options_dict\n",
    "\n",
    "\n",
    "for question in tqdm(test_samples, colour =\"green\"):\n",
    "    question_variants = []\n",
    "    prompt_variants = []\n",
    "    cot_responses = []\n",
    "    question_embedding = get_embedding(question[\"question\"])\n",
    "    distances, top_k_indices = knn.kneighbors([question_embedding], n_neighbors=5)\n",
    "    top_k_dicts = [filtered_questions_dict[i] for i in top_k_indices[0]]\n",
    "    question[\"outputs\"] = []\n",
    "    \n",
    "    for idx in range(5):\n",
    "        question_copy = question.copy()\n",
    "        shuffled_options = shuffle_option_labels(question[\"options\"])\n",
    "        inv_map = {v:k for k,v in shuffled_options.items()}\n",
    "        \n",
    "        question_copy[\"options\"] = shuffled_options\n",
    "        question_copy[\"answer_idx\"] = inv_map[question_copy[\"answer\"]]\n",
    "        question_variants.append(question_copy)\n",
    "        prompt = build_few_shot_prompt(system_prompt,  question_copy, top_k_dicts)\n",
    "        prompt_variants.append(prompt)\n",
    "    \n",
    "    for prompt in tqdm(prompt_variants):\n",
    "        response = get_response(prompt, model_name=\"gpt-4o\", max_tokens=500)\n",
    "        cot_responses.append(response)\n",
    "    \n",
    "    for question_sample, answer in zip(question_variants, cot_responses):\n",
    "        if validate_response(answer):\n",
    "            cot, pred_ans = parse_answer(answer)\n",
    "            \n",
    "        else:\n",
    "            cot = \"\"\n",
    "            pred_ans = \"\"\n",
    "                \n",
    "        question[\"outputs\"].append({\"question\": question_sample[\"question\"], \"options\": question_sample[\"options\"], \"cot\": cot, \"pred_ans\": question_sample[\"options\"].get(pred_ans, \"\")})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5051c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl_file(\"final_processed_test_set_responses_medprompt.jsonl\", test_samples )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135e7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = read_jsonl_file(\"final_processed_test_set_responses_medprompt.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def find_mode_string_list(string_list):\n",
    "    \"\"\"\n",
    "    Finds the most frequently occurring strings.\n",
    "\n",
    "    Parameters:\n",
    "    string_list (list of str): A list of strings.\n",
    "    Returns:\n",
    "    list of str or None: A list containing the most frequent string(s) from the input list.\n",
    "                         Returns None if the input list is empty.\n",
    "    \"\"\"    \n",
    "    if not string_list:\n",
    "        return None  \n",
    "\n",
    "    string_counts = Counter(string_list)\n",
    "    max_freq = max(string_counts.values())\n",
    "    mode_strings = [string for string, count in string_counts.items() if count == max_freq]\n",
    "    return mode_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83053aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0 \n",
    "\n",
    "for idx,item in enumerate(test_samples):\n",
    "    print(idx)\n",
    "    pred_ans = [x[\"pred_ans\"] for x in item[\"outputs\"]]\n",
    "    freq_ans = find_mode_string_list(pred_ans)\n",
    "    \n",
    "    if len(freq_ans) > 1:\n",
    "        final_prediction = \"\"\n",
    "    \n",
    "    else:\n",
    "        final_prediction = freq_ans[0]\n",
    "        \n",
    "    if final_prediction == item[\"answer\"]:\n",
    "        ctr +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45f0c50",
   "metadata": {},
   "source": [
    "## Zero shot evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4626ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_predictions = []\n",
    "\n",
    "for item in tqdm(test_samples):\n",
    "    messages = build_zero_shot_prompt(system_zero_shot_prompt, item)\n",
    "    response = get_response(messages, \"gpt-4o\", max_tokens=50)\n",
    "    pred_option = extract_ans_option(response.split(\"\\n\")[-1])\n",
    "    zero_shot_predictions.append(pred_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d324f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr =0 \n",
    "for gt,pred in zip(test_samples, zero_shot_predictions):\n",
    "    if pred == gt[\"answer_idx\"]:\n",
    "        ctr +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr / 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"zero_shot_predictions.json\", \"w\") as f:\n",
    "    f.write(json.dumps({\"predictions\": zero_shot_predictions}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414ebc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_predictions = json.loads(open(\"zero_shot_predictions.json\").read())[\"predictions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6095a",
   "metadata": {},
   "source": [
    "## Random few-shot evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca200dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_examples = random.sample(filtered_questions_dict, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed9162",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_predictions = []\n",
    "for item in tqdm(test_samples):\n",
    "    messages = build_few_shot_prompt(system_zero_shot_prompt, item, few_shot_examples, include_cot=False)\n",
    "    response = get_response(messages, \"gpt-4o\", max_tokens=50)\n",
    "    pred_option = extract_ans_option(response.split(\"\\n\")[-1])\n",
    "    few_shot_predictions.append(pred_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7145ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr =0 \n",
    "for gt,pred in zip(test_samples, few_shot_predictions):\n",
    "    if pred == gt[\"answer_idx\"]:\n",
    "        ctr +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746f773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr / 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e98ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"few_shot_predictions.json\", \"w\") as f:\n",
    "    f.write(json.dumps({\"predictions\": few_shot_predictions}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e488b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"few_shot_examples.json\", \"w\") as f:\n",
    "    f.write(json.dumps(few_shot_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7ced04",
   "metadata": {},
   "source": [
    "## Random few-shot evaluation with CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63835ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_cot_predictions = []\n",
    "for item in tqdm(test_samples):\n",
    "    messages = build_few_shot_prompt(system_zero_shot_prompt, item, few_shot_examples, include_cot=True)\n",
    "    answer = get_response(messages, \"gpt-4o\", max_tokens=500)\n",
    "    if validate_response(answer):\n",
    "        cot, pred_ans = parse_answer(answer)\n",
    "    else:\n",
    "        cot = \"\"\n",
    "        pred_ans = \"\"\n",
    "    few_shot_cot_predictions.append({\"cot\": cot, \"pred_ans\": pred_ans})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40294cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr =0 \n",
    "for gt,pred in zip(test_samples, few_shot_cot_predictions):\n",
    "    if pred[\"pred_ans\"] == gt[\"answer_idx\"]:\n",
    "        ctr +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be9dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"few_shot_predictions_cot.json\", \"w\") as f:\n",
    "    f.write(json.dumps({\"predictions\": few_shot_cot_predictions}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
