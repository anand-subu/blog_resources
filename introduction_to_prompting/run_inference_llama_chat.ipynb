{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff1289-7310-4d18-99bb-cddda849ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78bb06-5dd8-4b6b-8115-a89f7371a183",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34fae9e-2411-4fc2-bcbd-277d1a2c6c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",  torch_dtype=torch.bfloat16).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5896f301-89af-4329-b6d8-191f460b5f9f",
   "metadata": {},
   "source": [
    "## Load sub-sampled test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e4060",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = read_jsonl_file(\"USMLE_test_samples_300.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dde075-8b54-4e61-807c-c07610bf4da2",
   "metadata": {},
   "source": [
    "## Parse ground-truth and store answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34196aba-d6db-4a45-9057-eee1976bac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "\n",
    "for item in questions:\n",
    "    ans_options = item[\"options\"]\n",
    "    correct_ans_option = \"\"\n",
    "    for key,value in ans_options.items():\n",
    "        if value == item[\"answer\"]:\n",
    "            correct_ans_option = key\n",
    "            break\n",
    "            \n",
    "    ground_truth.append(correct_ans_option)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f033938-5c11-4d92-af9a-544d0ae48934",
   "metadata": {},
   "source": [
    "## Evaluate zero-shot LLama performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4732f8b-462d-4b31-a6b9-ec0b248a60d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_llama_answers = []\n",
    "for item in tqdm(questions):\n",
    "    zero_shot_prompt_messages = build_zero_shot_prompt(PROMPT, item)\n",
    "    prompt = tokenizer.apply_chat_template(zero_shot_prompt_messages, tokenize=False)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=10, do_sample=False)\n",
    "    \n",
    "    # https://github.com/huggingface/transformers/issues/17117#issuecomment-1124497554\n",
    "    gen_text = tokenizer.batch_decode(outputs.detach().cpu().numpy()[:, input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
    "    zero_shot_llama_answers.append(gen_text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514f836-82c2-41b5-9db2-ee1e1b360317",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_llama_predictions = [parse_answer(x) for x in zero_shot_llama_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0a6f9-7547-45fd-8726-1d1db25a270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_accuracy(ground_truth, zero_shot_llama_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcda3653-f87e-4670-a1dc-6dcb30c2b1f0",
   "metadata": {},
   "source": [
    "## Evaluate few-shot LLama performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf995f-0248-45e3-b888-923d59c8ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompts = read_jsonl_file(\"USMLE_few_shot_samples.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3affe58e-d258-42cc-a6a6-8add4ecb76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_llama_answers = []\n",
    "for item in tqdm(questions):\n",
    "    few_shot_prompt_messages = build_few_shot_prompt(PROMPT, item, few_shot_prompts)\n",
    "    prompt = tokenizer.apply_chat_template(few_shot_prompt_messages, tokenize=False)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=10, do_sample=False)\n",
    "    gen_text = tokenizer.batch_decode(outputs.detach().cpu().numpy()[:, input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
    "    few_shot_llama_answers.append(gen_text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434bfae9-37c9-498e-af12-e629aaa1952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_llama_predictions = [parse_answer(x) for x in few_shot_llama_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08138b70-c887-43e9-929d-4e8d09f90f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_accuracy(ground_truth, few_shot_llama_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aef0b3",
   "metadata": {},
   "source": [
    "## Evaluate CoT LLama performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da83a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_llama_answers = []\n",
    "for item in tqdm(questions):\n",
    "    cot_prompt = build_cot_prompt(COT_INSTRUCTION, item, COT_EXAMPLES)\n",
    "    prompt = tokenizer.apply_chat_template(cot_prompt, tokenize=False)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=100, do_sample=False)\n",
    "    gen_text = tokenizer.batch_decode(outputs.detach().cpu().numpy()[:, input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
    "    cot_llama_answers.append(gen_text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71552e53-197d-4e94-a465-3b6d3da934b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_llama_predictions = [parse_answer_cot(x) for x in cot_llama_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca5dfcc-8ed2-4f0e-aa1f-7a1a81465ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_accuracy(ground_truth, cot_llama_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db4571-8144-460d-8e4e-557f2f2a1733",
   "metadata": {},
   "source": [
    "## Dump all outputs and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba6db4-fea3-4194-bbaa-ab77fde37ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_llama_df = pd.DataFrame([[x,y] for x,y in zip(zero_shot_llama_answers, zero_shot_llama_predictions)])\n",
    "zero_shot_llama_df.columns = [\"Predicted String\", \"Extracted Option\"]\n",
    "zero_shot_llama_df.to_csv(\"llama_zero_shot_answers_dump.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d5d035-3149-4a01-ae10-9904765b7714",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_llama_df = pd.DataFrame([[x,y] for x,y in zip(few_shot_llama_answers, few_shot_llama_predictions)])\n",
    "few_shot_llama_df.columns = [\"Predicted String\", \"Extracted Option\"]\n",
    "few_shot_llama_df.to_csv(\"llama_few_shot_answers_dump.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf694e29-8eb7-4511-a85c-834942155b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_llama_df = pd.DataFrame([[x,y] for x,y in zip(cot_llama_answers, cot_llama_predictions)])\n",
    "cot_llama_df.columns = [\"Predicted String\", \"Extracted Option\"]\n",
    "cot_llama_df.to_csv(\"llama_cot_answers_dump.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
